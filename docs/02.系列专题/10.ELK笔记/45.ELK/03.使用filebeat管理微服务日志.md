---
title: 使用filebeat管理微服务日志
titleTag: 原创
date: 2019-01-05 22:49:26
permalink: /pages/2369.html
categories: 
  - 系列专题
  - ELK笔记
  - ELK
tags: 
  - elk
  - filebeat

description: 
---

# 微服务日志打印。

上边是输出了nginx日志，从而进行展示，以及各种绘图分析，而现在的需求是，要将微服务当中的日志汇总到elk当中以便开发查询日志定位问题。

都知道，微服务第一个特点就是，多，不仅项目多，而且往往单台主机当中也会有多个应用，因此多个日志文件情况下，如何处理才更加快速便捷呢，这里使用了filebeat来作为日志转发组件。

架构如图：

![image](http://t.eryajf.net/imgs/2021/09/0ff793c0152b7524.jpg)

### 1，配置filebeat。

主机规划如下图简示：

|      主机      |             组件             |
| :------------: | :--------------------------: |
| 192.168.100.21 | spring-cloud，filebeat-6.5.3 |
| 192.168.100.21 | spring-cloud，filebeat-6.5.3 |
| 192.168.10.10  |     logstash-6.5.3，elk      |

像刚刚那样，配置好yun源，然后直接安装。

```
yum -y install filebeat
```

然后来配置filebeat。

```yaml
cat > /etc/filebeat/filebeat.yml << EOF
filebeat.inputs:
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-config-server/normal/*.log
  type: "wf1-config"
  fields:
    logsource: 192.168.100.21
    logtype: wf1-config
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-eureka-server/normal/*.log
  type: "wf1-eureka"
  fields:
    logsource: 192.168.100.21
    logtype: wf1-eureka
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-gateway-server/normal/*.log
  type: "wf1-gateway"
  fields:
    logsource: 192.168.100.21
    logtype: wf1-gateway
output.logstash:
  hosts: ["192.168.10.10:5044"]
EOF
```

- 多个input定义多个应用日志路径，且可以用*.log进行匹配，默认读取目录下最新的日志。
- 每个里边都定义一个type类型，从而便于上下文衔接。
- 最后定义日志输出到elk的logstash的5044端口。

再去配置一下另外一台主机。

```yaml
cat > /etc/filebeat/filebeat.yml << EOF
filebeat.inputs:
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-activity-service/normal/*.log
  type: "wf5-activity"
  fields:
    logsource: 192.168.100.25
    logtype: wf5-activity
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-order-service/normal/*.log
  type: "wf5-order"
  fields:
    logsource: 192.168.100.25
    logtype: wf5-order
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-user-service/normal/*.log
  type: "wf5-user"
  fields:
    logsource: 192.168.100.25
    logtype: wf5-user
- input_type: log
  paths:
    - /home/ishangjie/ishangjie-thirdparty-service/normal/*.log
  type: "wf5-thirdparty"
  fields:
    logsource: 192.168.100.25
    logtype: wf5-thirdparty
output.logstash:
  hosts: ["192.168.10.10:5045"]
EOF
```

- 基本上配置与上边差不多，需要注意的一个地方就是output的logstash的端口，与上台主机不要一致，因为我们要启动多个实例进行管理的。

启动filebeat。

```sh
systemctl enable filebeat
systemctl start filebeat
systemctl status filebeat
```

### 2，配置logstash。

针对上边两个主机转过来的日志，在elk主机上添加相对应的配置进行接收。

`A`:

```json
cat > /etc/logstash/conf.d/wf1.conf << EOF
input {
 beats {
   port => "5044"
   host => "192.168.100.21"
  }
}
filter {
  if [fields][logtype] == "wf1-config" {
      json {
      source => "message"
      target => "data"
    }
  }
  if [fields][logtype] == "wf1-eureka" {
    json {
      source => "message"
      target => "data"
    }
  }
  if [fields][logtype] == "wf1-gateway" {
    json {
      source => "message"
      target => "data"
    }
  }
}
output {
  if [fields][logtype] == "wf1-config" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf1-config-%{+YYYY.MM.dd}"
    }
  }
  if [fields][logtype] == "wf1-eureka" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf1-eureka-%{+YYYY.MM.dd}"
    }
  }
  if [fields][logtype] == "wf1-gateway" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf1-gateway-%{+YYYY.MM.dd}"
    }
  }
}
EOF
```

`B`：

```json
cat > /etc/logstash/conf.d/wf5.conf << EOF
input {
 beats {
   port => 5052
   host => "192.168.100.25"
  }
}
filter {
  if [fields][logtype] == "wf5-activity" {
      json {
      source => "message"
      target => "data"
    }
  }
  if [fields][logtype] == "wf5-order" {
    json {
      source => "message"
      target => "data"
    }
  }
  if [fields][logtype] == "wf5-user" {
    json {
      source => "message"
      target => "data"
    }
  }
  if [fields][logtype] == "wf5-thirdparty" {
    json {
      source => "message"
      target => "data"
    }
  }
}
output {
  if [fields][logtype] == "wf5-activity" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf5-activity-%{+YYYY.MM.dd}"
    }
  }
  if [fields][logtype] == "wf5-order" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf5-order-%{+YYYY.MM.dd}"
    }
  }
  if [fields][logtype] == "wf5-user" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf5-user-%{+YYYY.MM.dd}"
    }
  }
  if [fields][logtype] == "wf5-thirdparty" {
    elasticsearch {
      hosts => ["127.0.0.1:9200"]
      index => "wf5-thirdparty-%{+YYYY.MM.dd}"
    }
  }
}
EOF
```

- 这里通过端口作为豁口，让彼此成为连接，注意要一一对应。
- 照单全收日志，然后转手发给本机的es同学。

启动这两个实例。

```sh
nohup /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/wf1.conf --path.data=/usr/share/logstash/data5 &> /logs/logstash_nohup/wf1.out &
nohup /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/wf5.conf --path.data=/usr/share/logstash/data9 &> /logs/logstash_nohup/wf5.out &
```

启动之后可以按上边演示过的步骤，在kibana当中添加索引，然后查看日志。

## 3，合理规划。

- 关于索引。
  - 上边的方式是一个服务配置了一个索引，众所周知，微服务第一大特点就是多，两个环境下来，发现按这种方式分配索引的话，会导致es里边集聚很多的索引。这是其一。
- 关于端口。
  - 按上边的思路，基本上是外部的一台主机，就对应启动了一个端口，这样很容易端口浪费，所以可以进行一下合理规划与配置。
- 解决上边两个问题。
  - 索引的话，我这边规划的是一台主机一个索引，而非一个服务一个索引。如此算下来，可以从原来二三十个索引缩减到十个以内。当然还可以从其他维度来进行区分。具体操作的办法非常简单，那就是在配置logstash实例的时候，在output处索引归拢即可。
  - 端口方面，我的规划是一类环境公用一个端口，原来预发线上一共十台服务用了十个端口，现在预发用一个，线上用一个。具体操作就是filebeat客户端端口统一，然后logstash实例汇总到一起即可。
